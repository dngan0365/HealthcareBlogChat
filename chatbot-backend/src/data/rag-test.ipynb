{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.10.28\n",
      "  Using cached llama_index-0.10.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.28 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index==0.10.28) (0.9.48.post4)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.59.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.4.2)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.26.4)\n",
      "Requirement already satisfied: pandas in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.10.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.17.1)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.28) (0.1.19)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28) (0.5.19)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (2.6)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28) (8.1.8)\n",
      "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28)\n",
      "  Using cached llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Using cached llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "  Using cached llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.8.0)\n",
      "Requirement already satisfied: certifi in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface 0.5.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-llms-gemini 0.4.3 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-vector-stores-weaviate 1.3.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.11.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.17.0)\n",
      "Using cached llama_index-0.10.28-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Installing collected packages: pypdf, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 5.1.0\n",
      "    Uninstalling pypdf-5.1.0:\n",
      "      Successfully uninstalled pypdf-5.1.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.10.post1\n",
      "    Uninstalling llama-index-core-0.12.10.post1:\n",
      "      Successfully uninstalled llama-index-core-0.12.10.post1\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.5.19\n",
      "    Uninstalling llama-parse-0.5.19:\n",
      "      Successfully uninstalled llama-parse-0.5.19\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.4.3\n",
      "    Uninstalling llama-index-readers-file-0.4.3:\n",
      "      Successfully uninstalled llama-index-readers-file-0.4.3\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.3.13\n",
      "    Uninstalling llama-index-llms-openai-0.3.13:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.3.13\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.6.3\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.6.3:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.6.3\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.3.1\n",
      "    Uninstalling llama-index-embeddings-openai-0.3.1:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.3.1\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.4.0\n",
      "    Uninstalling llama-index-readers-llama-parse-0.4.0:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.4.0\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.4.2\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.4.2:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.4.2\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.4.0\n",
      "    Uninstalling llama-index-cli-0.4.0:\n",
      "      Successfully uninstalled llama-index-cli-0.4.0\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.4.1\n",
      "    Uninstalling llama-index-agent-openai-0.4.1:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.4.1\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.3.1\n",
      "    Uninstalling llama-index-program-openai-0.3.1:\n",
      "      Successfully uninstalled llama-index-program-openai-0.3.1\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.3.0\n",
      "    Uninstalling llama-index-question-gen-openai-0.3.0:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.3.0\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.12.10\n",
      "    Uninstalling llama-index-0.12.10:\n",
      "      Successfully uninstalled llama-index-0.12.10\n",
      "Successfully installed llama-index-0.10.28 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 pypdf-4.3.1\n",
      "Requirement already satisfied: llama-index-llms-gemini in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: llama-index in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.10.28)\n",
      "Requirement already satisfied: google-generativeai>=0.5.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-llms-gemini) (0.8.3)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-gemini)\n",
      "  Using cached llama_index_core-0.12.10.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (0.1.13)\n",
      "INFO: pip is looking at multiple versions of llama-index to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index\n",
      "  Using cached llama_index-0.12.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.13-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.158.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.37.0)\n",
      "Requirement already satisfied: protobuf in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.3)\n",
      "Requirement already satisfied: pydantic in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.10.5)\n",
      "Requirement already satisfied: tqdm in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.25.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.59.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: numpy in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.17.1)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.8)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9)\n",
      "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-cloud>=0.1.5->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.12.14)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.25.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Using cached llama_index-0.12.10-py3-none-any.whl (6.8 kB)\n",
      "Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.12.10.post1-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_llms_openai-0.3.13-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.3-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_parse-0.5.19-py3-none-any.whl (15 kB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: pypdf, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.4.9\n",
      "    Uninstalling llama-parse-0.4.9:\n",
      "      Successfully uninstalled llama-parse-0.4.9\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.1.33\n",
      "    Uninstalling llama-index-readers-file-0.1.33:\n",
      "      Successfully uninstalled llama-index-readers-file-0.1.33\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.1.31\n",
      "    Uninstalling llama-index-llms-openai-0.1.31:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.1.31\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.1.6\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.1.6:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.1.6\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.1.11\n",
      "    Uninstalling llama-index-embeddings-openai-0.1.11:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.1.11\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.1.6\n",
      "    Uninstalling llama-index-readers-llama-parse-0.1.6:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.1.6\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.1.9\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.1.9:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.1.9\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.1.13\n",
      "    Uninstalling llama-index-cli-0.1.13:\n",
      "      Successfully uninstalled llama-index-cli-0.1.13\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.2.9\n",
      "    Uninstalling llama-index-agent-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.2.9\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.1.7\n",
      "    Uninstalling llama-index-program-openai-0.1.7:\n",
      "      Successfully uninstalled llama-index-program-openai-0.1.7\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.1.3\n",
      "    Uninstalling llama-index-question-gen-openai-0.1.3:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.1.3\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.28\n",
      "    Uninstalling llama-index-0.10.28:\n",
      "      Successfully uninstalled llama-index-0.10.28\n",
      "Successfully installed llama-index-0.12.10 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.10.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.13 llama-index-multi-modal-llms-openai-0.4.2 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.3 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.19 pypdf-5.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-parse in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.5.19)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (8.1.8)\n",
      "Requirement already satisfied: llama-index-core>=0.11.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (0.12.10.post1)\n",
      "Requirement already satisfied: pydantic!=2.10 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (2.10.5)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from click<9.0.0,>=8.1.7->llama-parse) (0.4.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
      "Requirement already satisfied: numpy in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.17.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic!=2.10->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic!=2.10->llama-parse) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.18.3)\n",
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.25.1)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.10.28\n",
    "%pip install llama-index-llms-gemini llama-index\n",
    "%pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-bfQQ5jVwQR1ne8FnmRvSHqNNc7pP9fo4p24QRMS7h74n1w1r\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAxAkyAHaMx7xNxkF5zazokhtZLfp7x6zU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_engineer\\Doan\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.llms.databricks import Databricks\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Tải mô hình embedding\n",
    "#embed_model = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder') \n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-pro\",\n",
    "             api_key=\"AIzaSyAxAkyAHaMx7xNxkF5zazokhtZLfp7x6zU\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tam_li': 'https://igiaoduc.vn/content/uploads/elearning/11qd4216phe-duyet-so-tay-tvtlbgddt-3218329.pdf', 'Dinh_duong': 'https://benhvienthammynaman.com/wp-content/uploads/2024/03/Dinh-duong-chia-khoa-vang-cho-suc-khoe.pdf'}\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://igiaoduc.vn/content/uploads/elearning/11qd4216phe-duyet-so-tay-tvtlbgddt-3218329.pdf\",\n",
    "       \"https://benhvienthammynaman.com/wp-content/uploads/2024/03/Dinh-duong-chia-khoa-vang-cho-suc-khoe.pdf\",\n",
    "       #\"https://viendinhduong.vn/FileUpload/Documents/2020/Dinh%20Duong%20Va%20An%20Toan%20Thuc%20Pham%20-%20Bo%20Y%20Te.pdf\",\n",
    "       #\"https://swsphn.com.au/wp-content/uploads/2022/06/Live_Well_Guide_wb__Vietnamese_LR.pdf\",\n",
    "       ]\n",
    "\n",
    "titles = [\n",
    "    \"Tam_li\",\n",
    "    \"Dinh_duong\",\n",
    "    #\"DD_ATTP\",\n",
    "    #\"Loi_song\"\n",
    "]\n",
    "\n",
    "book_dict = {titles[i]: urls[i] for i in range(len(urls))}\n",
    "print(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 94b276d7-4340-4853-9362-2a8cc982486d\n",
      "### json_objs Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 1\n",
      "Keys of first item: ['pages', 'job_metadata', 'job_id', 'file_path']\n",
      "----------------------\n",
      "### json_list Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 123\n",
      "Keys of first item: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Sample Data (First Item): {'page': 1, 'text': '            Nutrition for Life\\n        Lisa Hark, PhD & Dr; Darwin Deen\\n    Chia khoaDinhduongktoeg\\n      cho sUc\\n3\\n2\\n   PN NHA XUAT BAN PHU NU     NUTRILITE', 'md': '# Nutrition for Life\\n\\n# Lisa Hark, PhD & Dr. Darwin Deen\\n\\nChia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'images': [{'name': 'img_p0_1.png', 'height': 2200, 'width': 1565, 'x': -0.24782300000000035, 'y': 0, 'original_width': 1565, 'original_height': 2200, 'ocr': [{'x': 463, 'y': 47, 'w': 575, 'h': 79, 'confidence': '0.73625183285983', 'text': 'Nutrition for Life'}, {'x': 339, 'y': 148, 'w': 834, 'h': 61, 'confidence': '0.7505294609100561', 'text': 'Lisa Hark, PhD & Dr; Darwin Deen'}, {'x': 311, 'y': 221, 'w': 894, 'h': 266, 'confidence': '0.9989321945557518', 'text': 'Dinhduong'}, {'x': 177, 'y': 432, 'w': 751, 'h': 157, 'confidence': '0.9967959505448877', 'text': 'Chia khoa'}, {'x': 260, 'y': 579, 'w': 577, 'h': 148, 'confidence': '0.8019852041826463', 'text': 'cho sUc'}, {'x': 846, 'y': 428, 'w': 500, 'h': 316, 'confidence': '0.5082430385500368', 'text': 'ktoeg'}, {'x': 6, 'y': 1756, 'w': 52, 'h': 132, 'confidence': '0.25177512642062894', 'text': '3'}, {'x': 1, 'y': 1883, 'w': 61, 'h': 121, 'confidence': '0.5116835424123565', 'text': '2'}, {'x': 157, 'y': 2057, 'w': 50, 'h': 40, 'confidence': '0.8614639207754446', 'text': 'PN'}, {'x': 230, 'y': 2064, 'w': 432, 'h': 52, 'confidence': '0.8886106524629317', 'text': 'NHA XUAT BAN PHU NU'}, {'x': 1080, 'y': 2060, 'w': 372, 'h': 54, 'confidence': '0.8908326294233071', 'text': 'NUTRILITE'}]}], 'charts': [], 'items': [{'type': 'heading', 'lvl': 1, 'value': 'Nutrition for Life', 'md': '# Nutrition for Life', 'bBox': {'x': 180.96, 'y': 16.94, 'w': 225.04, 'h': 28.47}}, {'type': 'heading', 'lvl': 1, 'value': 'Lisa Hark, PhD & Dr. Darwin Deen', 'md': '# Lisa Hark, PhD & Dr. Darwin Deen', 'bBox': {'x': 0, 'y': 0, 'w': 612, 'h': 792}}, {'type': 'text', 'value': 'Chia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'md': 'Chia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'bBox': {'x': 61.2, 'y': 154.23, 'w': 506.83, 'h': 608.26}}], 'status': 'OK', 'links': [], 'width': 612, 'height': 792, 'triggeredAutoMode': False, 'structuredData': None, 'noStructuredContent': False, 'noTextContent': False}\n",
      "----------------------\n",
      "Page 1 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 2 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 3 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 4 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 5 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 6 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 7 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 8 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 9 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 10 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 11 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 12 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "### docs Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 12\n",
      "Sample Document Metadata: {'page_label': 9}\n",
      "Sample Document Text Type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import Document\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "def _load_data(file_path: str) -> list[Document]:\n",
    "    parser = LlamaParse(result_type=\"text\")\n",
    "    json_objs = parser.get_json_result(file_path)\n",
    "    \n",
    "    # In thông tin cơ bản của json_objs\n",
    "    print(\"### json_objs Structure ###\")\n",
    "    print(f\"Type: {type(json_objs)}\")\n",
    "    if isinstance(json_objs, list):\n",
    "        print(f\"Length: {len(json_objs)}\")\n",
    "        print(f\"Keys of first item: {list(json_objs[0].keys())}\")\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    json_list = json_objs[0][\"pages\"]  # Lấy danh sách các trang\n",
    "    print(\"### json_list Structure ###\")\n",
    "    print(f\"Type: {type(json_list)}\")\n",
    "    if isinstance(json_list, list):\n",
    "        print(f\"Length: {len(json_list)}\")\n",
    "        print(f\"Keys of first item: {list(json_list[0].keys())}\")\n",
    "        print(f\"Sample Data (First Item): {json_list[0]}\")\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    docs = []\n",
    "    for i, item in enumerate(json_list[8:20]):  # Lấy 10 trang đầu\n",
    "        print(f\"Page {i + 1} Keys: {list(item.keys())}\")\n",
    "        print(f\"Metadata Type: {type(item['text'])} - Page Label Type: {type(item['page'])}\")\n",
    "        doc = Document(\n",
    "            text=item[\"text\"],\n",
    "            metadata={\"page_label\": item[\"page\"]},\n",
    "        )\n",
    "        docs.append(doc)\n",
    "\n",
    "    print(\"### docs Structure ###\")\n",
    "    print(f\"Type: {type(docs)}\")\n",
    "    print(f\"Length: {len(docs)}\")\n",
    "    if docs:\n",
    "        print(f\"Sample Document Metadata: {docs[0].metadata}\")\n",
    "        print(f\"Sample Document Text Type: {type(docs[0].text)}\")\n",
    "    \n",
    "    return docs\n",
    "documents = _load_data(urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_list = []\n",
    "for title in titles:\n",
    "    docs = _load_data(book_dict[title])\n",
    "    documents_list.append(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'list'>\n",
      "Length: 36\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SentenceSplitter,\n",
    "    SemanticSplitterNodeParser,\n",
    ")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=7, breakpoint_percentile_threshold=50, embed_model=Settings.embed_model\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Type: {type(nodes)}\")\n",
    "if isinstance(nodes, list):\n",
    "    print(f\"Length: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: d0a524a5-cde4-478d-86aa-465cdd7a33ac\n",
      "Text: Bánh mì              14              12               74\n",
      "4,1            B1, Fol, Nia/Fe, K, Mg, P, Zn  nguyên cám  Gạo lứt\n",
      "9               10               81                  1,7\n",
      "B1, Nia/Mg, P, Zn  Đậu que              0               9\n",
      "91                  4              A, Fol, K/K  Táo  ...\n",
      "Node ID: 1d82d735-7e6b-47ae-bbc0-7df72c6293eb\n",
      "Text: Năng Lượng Từ Thức Ăn           Ngoài việc cung cấp dưỡng chất,\n",
      "thức ăn còn       cung cấp năng lượng cho cơ thể. Khoảng 1/2 đến\n",
      "2/3 số năng lượng từ thức ăn được cơ thể dùng để       duy trì các\n",
      "chức năng sống cơ bản – các hoạt động       được thực hiện một cách vô\n",
      "thức như duy trì nhịp       tim, hít thở, điều hòa thân nhiệt… Lượng\n",
      "năng ...\n",
      "Node ID: 32575d86-e3e3-4f46-bc93-30c7ad81efa9\n",
      "Text: Tốc độ chuyển hóa đạt ở\n",
      "Node ID: 054f54f0-889a-437f-8d0f-0d234651a62f\n",
      "Text: làm việc trong văn phòng mức cao nhất khi chúng ta còn nhỏ và\n",
      "giảm                                              dần sau 10 tuổi. Do\n",
      "nam giới có khối lượng cơ bắp nhiều hơn nên thường có tốc độ chuyển\n",
      "hóa cao hơn, và vì vậy mà cần nhiều năng lượng hơn phụ nữ. Do khối\n",
      "lượng cơ bắp giảm dần theo tuổi tác nên người già có tốc độ chuyển hóa\n",
      "thấp hơn ...\n",
      "Node ID: ce0d6a4f-9f6a-4295-855f-1cfd43d41d89\n",
      "Text: Tuy nhiên, vì       1 calo tương ứng với một lượng năng lượng\n",
      "rất nhỏ nên đơn vị kilô calo       (kcal)thường được sử dụng.\n",
      "Node ID: fb7f0c70-3a6f-4644-9fdc-c96533d99129\n",
      "Text: (1 kcal = 1.000 cal).\n",
      "Node ID: 3863ea18-d273-44db-918f-e594584dac34\n",
      "Text: Mỗi loại dưỡng chất sinh ra một lượng năng lượng nhất định, ví\n",
      "dụ như:          ◈ 100g protein: 400kcal          ◈ 100g carbohydrate:\n",
      "400kcal          ◈ 100g chất béo: 900kcal\n",
      "Node ID: db339fdc-84d1-4a0b-93f9-98955dde5ef9\n",
      "Text: CƠ THỂ XỬ LÝ THỨC ĂN NHƯ THẾ NÀO?     Trước khi được sử dụng,\n",
      "các chất dinh dưỡng trong thức ăn phải được chuyển hóa thành dạng đơn\n",
      "giản mà các tế bào trong cơ thể có thể hấp thu. Quá trình này có thể\n",
      "mất từ một đến ba ngày, bắt đầu từ khoang miệng và kết thúc bằng việc\n",
      "tống xuất chất thải ra khỏi cơ thể.     Thức ăn sẽ trải qua một quá\n",
      "trình bi...\n",
      "Node ID: 239446f6-3835-40f2-b3fa-328aa7306db2\n",
      "Text: Phần thức ăn không được tiêu hóa và hấp thu sẽ được thải ra\n",
      "ngoài.\n",
      "Node ID: 95d88038-c539-4a12-8dbf-c97e315c1036\n",
      "Text: He tieu hoa                Mieng_\n",
      "Tuyen                                                          nuoc\n",
      "bot        Nap thanh                                             Gan\n",
      "quan               Thuc               quan          Tui mat\n",
      "Ruqt non             Tuyen  ...\n",
      "Node ID: 8d4c4bb0-90d8-4b7d-aebd-c4ad3758f441\n",
      "Text: tiêu hóa thức ăn.\n",
      "Node ID: bae15754-eb49-4c56-95e0-ca00a9e7c933\n",
      "Text: Tuyến tụy:tiết men tiêu hóa vào ruột non.     Trực tràng:phân\n",
      "được giữ tại đây trước khi được thải ra khỏi cơ thể.      Hậu môn:là\n",
      "nơi kết thúc của ống tiêu hóa, đảm nhiệm việc thải phân ra ngoài.\n",
      "Dạ dày:thức ăn lưu lại trong dạ dày khoảng 5 giờ để được bóp nát và\n",
      "hòa lẫn với dịch vị. Trong dịch vị có chứa axit giúp tiêu diệt vi\n",
      "khuẩn trong ...\n",
      "Node ID: bf79480a-e99a-409d-b93d-d54e61e31d41\n",
      "Text: Tại đây, thức ăn được hòa trộn với nhiều dịch tiêu hóa nữa.\n",
      "Node ID: 2072758d-bd29-4f63-a755-e414d6f7cd4b\n",
      "Text: Các chất dinh dưỡng, bao gồm vitamin và khoáng chất, được hấp\n",
      "thu vào máu.\n",
      "Node ID: a1607816-05d5-4da4-97c1-6f161a7a027f\n",
      "Text: Ruột già:trong ruột già có chứa nhiều vi khuẩn đường ruột giúp\n",
      "tiếp tục tiêu hóa các dưỡng chất còn lại trong thức ăn.\n",
      "Node ID: eeecf2f8-1f8d-491f-8711-c5f1c77219cf\n",
      "Text: Nước và các dưỡng chất do vi khuẩn phân giải được hấp thu vào\n",
      "máu.\n",
      "Node ID: 6c97ae99-23bd-4667-96d2-cf45a82bc6d4\n",
      "Text: ____________________     Chú thích:      (*) Enzyme là những\n",
      "chất xúc tác sinh học có bản chất là protein.\n",
      "Node ID: c4155a17-a5c9-4b64-b2a2-7d38da0d9a43\n",
      "Text: Chúng xúc tác cho hầu hết các phản ứng chuyển hóa diễn ra trong\n",
      "cơ thể sống.\n",
      "Node ID: 277160d5-8490-41fb-a8f0-518290397749\n",
      "Text: Chất béo – Không nên quá sợ!\n",
      "Node ID: 8f7e5f87-34f1-4967-93d0-e5363784868b\n",
      "Text: Chất béo góp phần tạo thành màng tế bào và đóng vai trò cực kỳ\n",
      "quan trọng trong việc hấp thu các vitamin tan trong dầu như vitamin A,\n",
      "D, E và K.     Chất béo hình thành một lớp bảo vệ cho cơ thể, giúp duy\n",
      "trì thân nhiệt để cơ thể không bị ảnh hưởng khi nhiệt độ môi trường\n",
      "quá nóng hay quá lạnh. Đây cũng là nguồn năng lượng quan trọng của cơ\n",
      "thể\n",
      "Node ID: 76c2a2ae-718c-4948-8704-764df7b1e2eb\n",
      "Text: CHẤT BÉO– KHÔNG NÊN QUÁ SỢ!           Là một phần của các hợp\n",
      "chất được gọi là lipid, chất       béo được tìm thấy chủ yếu trong\n",
      "thịt, cá và một số loại       thực phẩm có nguồn gốc thực vật. Chất\n",
      "béo góp phần       tạo thành màng tế bào và đóng vai trò cực kỳ quan\n",
      "trọng trong việc hấp thu các vitamin tan trong dầu như       vitamin\n",
      "A, D, ...\n",
      "Node ID: 5959bbcc-2153-4a4e-93b6-ba3856e48809\n",
      "Text: nguy cơ mắc bệnh tim mạch.     Thực phẩm chứa nhiều chất béo bão\n",
      "hòa bao gồm: sản phẩm giàu chất béo có nguồn gốc từ sữa (bơ, phô mai,\n",
      "kem, sữa nguyên kem…), thịt có nhiều mỡ, xúc xích, mỡ động vật, nước\n",
      "thịt, dầu cọ, dầu dừa, da của các loại gia cầm (gà, vịt…).\n",
      "Axit béo                           ...\n",
      "Node ID: 226be6fb-b252-49ec-8902-b769adc8cbaf\n",
      "Text: Cholesterol là một chất giống như sáp ở trong máu.\n",
      "Node ID: b23c2be3-6125-4fa9-b139-0d2f99640170\n",
      "Text: Đây là thành tố chính yếu của       vách tế bào.\n",
      "Node ID: 6c25694f-a615-4de9-acfb-0977e992c418\n",
      "Text: Cholesterol cũng cần cho việc sản sinh các nội tiết tố, như nội\n",
      "tiết tố       sinh dục – estrogen và testosterone.\n",
      "Node ID: 1c7df12a-986e-4956-8193-4c0f7c701699\n",
      "Text: Cholesterol hiện diện với mật độ rất cao trong các tế bào.\n",
      "Node ID: d184e332-b463-4219-b0c0-75f6d2e3cc94\n",
      "Text: Nó có vai trò rất       quan trọng là bảo vệ não và hệ thần\n",
      "kinh.\n",
      "Node ID: 3056d949-0162-4bcb-aeaa-35272883888f\n",
      "Text: Vì vậy, không cần giới hạn lượng       cholesterol ăn vào đối\n",
      "với trẻ em dưới hai tuổi, đối tượng mà não bộ và hệ thần       kinh\n",
      "vẫn đang tiếp tục phát triển.\n",
      "Node ID: 5ebd767b-ac0a-4e7f-85cd-782268a03a8a\n",
      "Text: Cholesterol cũng cần thiết cho việc tạo ra axit mật (hỗ trợ cho\n",
      "sự hấp thu chất       béo từ thức ăn) và cần cho quá trình sản sinh\n",
      "vitamin D ở da.      Phần lớn nhu cầu cholesterol của cơ thể được đáp\n",
      "ứng bởi chính lượng cholesterol mà cơ thể tự tạo ra. Phần còn lại được\n",
      "đáp ứng từ cholesterol trong thức ăn (cholesterol được tìm thấy với\n",
      "hàm lư...\n",
      "Node ID: b4fd3d3b-72df-4b9c-8656-c02460ac5efd\n",
      "Text: Hãy khoanh tròn câu trả lời phù hợp với bạn nhất và kiểm tra số\n",
      "điểm của bạn.\n",
      "Node ID: c02efc18-63e8-4c83-bd29-f5442f472724\n",
      "Text: 1.\n",
      "Node ID: 24bce2e9-c2fe-4da0-ab0b-33394d2fe518\n",
      "Text: Bạn thường ăn món chiên (cả ít dầu/ngập dầu) bao nhiêu lần?\n",
      "Node ID: 0b66298d-8d6f-465e-b2a8-280f5e1ebe03\n",
      "Text: a) Mỗi tuần ba lần hoặc hơn           b) Khoảng một lần mỗi tuần\n",
      "c) Tối đa hai lần một tháng           2.Bạn thường dùng loại chất béo\n",
      "nào để nấu nướng?\n",
      "Node ID: f5ea0985-1065-46e1-8efd-a6a7c72a9ab0\n",
      "Text: a) Bơ động vật, mỡ lợn, hoặc mỡ bò     b) Bơ thực vật hoặc dầu\n",
      "thực vật     c) Dầu ô liu hoặc dầu hạt nho     3.\n",
      "Node ID: 61a66d55-4bfa-4a4c-bfb0-169c6005895f\n",
      "Text: Bạn thường dùng loại sữa nào để chế biến nước xốt và các món\n",
      "súp, chè?     a) Sữa nguyên kem hoặc kem     b) Sữa tách béo một phần\n",
      "c) Sữa tách béo toàn phần     4. Khi nấu rau củ quả, bạn có thêm bơ\n",
      "động vật vào không?     a) Luôn cho thêm bơ động vật vào     b) Thi\n",
      "thoảng có dùng bơ động vật     c) Không bao giờ cho thêm bơ động vật\n",
      "vào    ...\n",
      "Node ID: ea492536-d141-49d5-9812-f4b2230ba06e\n",
      "Text: TRẮC NGHIỆM\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "for i in range(len(nodes)):\n",
    "    print(nodes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "# cloud\n",
    "cluster_url = \"https://wly3tkm2tkewvzycwne6fa.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "api_key = \"ruGxCkA145k9qWxpoycebKHeLGxc9vtCnLWZ\"\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=cluster_url,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Dinh_duong\", text_key=\"content\")\n",
    "\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dict_keys(['text', 'content', '_node_type', 'page_label', 'document_id', 'relationships', 'ref_doc_id', '_node_content', 'doc_id', 'node_info'])\n",
      "['content', '_node_type', 'page_label', 'document_id', 'ref_doc_id', '_node_content', 'doc_id']\n",
      "{'content': 'làm việc trong văn phòng mức cao nhất khi chúng ta còn nhỏ và giảm\\n                                             dần sau 10 tuổi. Do nam giới có khối lượng cơ\\nbắp nhiều hơn nên thường có tốc độ chuyển hóa cao hơn, và vì vậy mà cần nhiều\\nnăng lượng hơn phụ nữ. Do khối lượng cơ bắp giảm dần theo tuổi tác nên người\\ngià có tốc độ chuyển hóa thấp hơn và cần ít năng lượng hơn.\\n\\n    Sau đây là các ví dụ về nhu cầu năng lượng cho các hoạt động khác nhau ở\\nngười trưởng thành:\\n    ◈Người ít vận động: 11,5kcal/ 450g trọng lượng cơ thể/ngày.\\n\\n    ◈Người chỉ vận động nhẹ: 13,5kcal/450g trọng lượng cơ thể/ngày.\\n    ◈Người vận động vừa phải và tập thể dục thường xuyên: 16kcal/450g trọng\\nlượng cơ thể/ngày.\\n\\n    ◈Người vận động nhiều, như các vận động viên thể thao, người lao động chân\\ntay và bệnh nhân đang trong quá trình hồi phục: 18kcal/450g trọng lượng cơ\\nthể/ngày.\\n\\n         Calo và năng lượng\\n         Năng lượng nhận được từ thức ăn được đo bằng đơn vị calo (cal). ', '_node_type': 'TextNode', 'page_label': 11.0, 'document_id': UUID('42cfe46a-9ec6-46e3-9e30-e410468ef446'), 'ref_doc_id': '42cfe46a-9ec6-46e3-9e30-e410468ef446', '_node_content': '{\"id_\": \"054f54f0-889a-437f-8d0f-0d234651a62f\", \"embedding\": null, \"metadata\": {\"page_label\": 11}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {\"1\": {\"node_id\": \"42cfe46a-9ec6-46e3-9e30-e410468ef446\", \"node_type\": \"4\", \"metadata\": {\"page_label\": 11}, \"hash\": \"2d9db457b2169620664d3d01f3407202d520deaccf60b35a502fc017fbc4e63f\", \"class_name\": \"RelatedNodeInfo\"}, \"3\": {\"node_id\": \"ce0d6a4f-9f6a-4295-855f-1cfd43d41d89\", \"node_type\": \"1\", \"metadata\": {}, \"hash\": \"e410ca8e94ce48434df92a14782e197a378499d0efc70c4335f0fb0ff558ce2f\", \"class_name\": \"RelatedNodeInfo\"}}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": 0, \"end_char_idx\": 966, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'doc_id': UUID('42cfe46a-9ec6-46e3-9e30-e410468ef446')}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"Dinh_duong\")\n",
    "\n",
    "i=0\n",
    "for item in collection.iterator():\n",
    "    print(i)\n",
    "    # In danh sách các keys\n",
    "    print(item.properties.keys())\n",
    "    \n",
    "    # Lọc ra các keys không phải 'None'\n",
    "    filtered_keys = [key for key in item.properties.keys() if item.properties[key] != None]\n",
    "    print(filtered_keys)\n",
    "    \n",
    "    # In giá trị của các keys đã lọc\n",
    "    filtered_values = {key: item.properties[key] for key in filtered_keys}\n",
    "    print(filtered_values)\n",
    "    print('-'*50)\n",
    "    # i+=1\n",
    "    if (i==0): break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.base.response.schema.Response'>\n",
      "> Source (Doc id: 054f54f0-889a-437f-8d0f-0d234651a62f): làm việc trong văn phòng mức cao nhất khi chúng ta còn nhỏ và giảm\n",
      "                              ...\n",
      "\n",
      "> Source (Doc id: 1d82d735-7e6b-47ae-bbc0-7df72c6293eb): Năng Lượng Từ Thức Ăn\n",
      "          Ngoài việc cung cấp dưỡng chất, thức ăn còn\n",
      "      cung cấp năng l...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Nhu cầu năng lượng cho người trưởng thành ít vận động là 11,5kcal/450g trọng lượng cơ thể/ngày.  Người vận động nhẹ cần 13,5kcal/450g trọng lượng cơ thể/ngày.  Người vận động vừa phải và tập thể dục thường xuyên cần 16kcal/450g trọng lượng cơ thể/ngày.  Cuối cùng, người vận động nhiều cần 18kcal/450g trọng lượng cơ thể/ngày.\n",
       "</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Nhu cầu năng lượng cho các hoạt động ở người trưởng thành là gì?\")\n",
    "print(type(response))\n",
    "print(response.get_formatted_sources())\n",
    "from IPython.display import display,Markdown\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
