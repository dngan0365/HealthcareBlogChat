{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.10.28\n",
      "  Using cached llama_index-0.10.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.28 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index==0.10.28) (0.9.48.post4)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.28)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.59.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.4.2)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.26.4)\n",
      "Requirement already satisfied: pandas in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.10.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.17.1)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.28) (0.1.19)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28) (0.5.19)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.28) (2.6)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28) (8.1.8)\n",
      "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.28)\n",
      "  Using cached llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Using cached llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "  Using cached llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (4.8.0)\n",
      "Requirement already satisfied: certifi in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface 0.5.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-llms-gemini 0.4.3 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-vector-stores-weaviate 1.3.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.11.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.28) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (3.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index==0.10.28) (1.17.0)\n",
      "Using cached llama_index-0.10.28-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Installing collected packages: pypdf, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 5.1.0\n",
      "    Uninstalling pypdf-5.1.0:\n",
      "      Successfully uninstalled pypdf-5.1.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.10.post1\n",
      "    Uninstalling llama-index-core-0.12.10.post1:\n",
      "      Successfully uninstalled llama-index-core-0.12.10.post1\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.5.19\n",
      "    Uninstalling llama-parse-0.5.19:\n",
      "      Successfully uninstalled llama-parse-0.5.19\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.4.3\n",
      "    Uninstalling llama-index-readers-file-0.4.3:\n",
      "      Successfully uninstalled llama-index-readers-file-0.4.3\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.3.13\n",
      "    Uninstalling llama-index-llms-openai-0.3.13:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.3.13\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.6.3\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.6.3:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.6.3\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.3.1\n",
      "    Uninstalling llama-index-embeddings-openai-0.3.1:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.3.1\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.4.0\n",
      "    Uninstalling llama-index-readers-llama-parse-0.4.0:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.4.0\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.4.2\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.4.2:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.4.2\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.4.0\n",
      "    Uninstalling llama-index-cli-0.4.0:\n",
      "      Successfully uninstalled llama-index-cli-0.4.0\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.4.1\n",
      "    Uninstalling llama-index-agent-openai-0.4.1:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.4.1\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.3.1\n",
      "    Uninstalling llama-index-program-openai-0.3.1:\n",
      "      Successfully uninstalled llama-index-program-openai-0.3.1\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.3.0\n",
      "    Uninstalling llama-index-question-gen-openai-0.3.0:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.3.0\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.12.10\n",
      "    Uninstalling llama-index-0.12.10:\n",
      "      Successfully uninstalled llama-index-0.12.10\n",
      "Successfully installed llama-index-0.10.28 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 pypdf-4.3.1\n",
      "Requirement already satisfied: llama-index-llms-gemini in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: llama-index in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.10.28)\n",
      "Requirement already satisfied: google-generativeai>=0.5.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-llms-gemini) (0.8.3)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-gemini)\n",
      "  Using cached llama_index_core-0.12.10.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (0.1.13)\n",
      "INFO: pip is looking at multiple versions of llama-index to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index\n",
      "  Using cached llama_index-0.12.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.13-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.158.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.37.0)\n",
      "Requirement already satisfied: protobuf in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.3)\n",
      "Requirement already satisfied: pydantic in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.10.5)\n",
      "Requirement already satisfied: tqdm in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.25.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.59.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: numpy in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.17.1)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.8)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9)\n",
      "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-cloud>=0.1.5->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.12.14)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.25.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Using cached llama_index-0.12.10-py3-none-any.whl (6.8 kB)\n",
      "Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.12.10.post1-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_llms_openai-0.3.13-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.3-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_parse-0.5.19-py3-none-any.whl (15 kB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: pypdf, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.4.9\n",
      "    Uninstalling llama-parse-0.4.9:\n",
      "      Successfully uninstalled llama-parse-0.4.9\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.1.33\n",
      "    Uninstalling llama-index-readers-file-0.1.33:\n",
      "      Successfully uninstalled llama-index-readers-file-0.1.33\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.1.31\n",
      "    Uninstalling llama-index-llms-openai-0.1.31:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.1.31\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.1.6\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.1.6:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.1.6\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.1.11\n",
      "    Uninstalling llama-index-embeddings-openai-0.1.11:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.1.11\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.1.6\n",
      "    Uninstalling llama-index-readers-llama-parse-0.1.6:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.1.6\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.1.9\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.1.9:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.1.9\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.1.13\n",
      "    Uninstalling llama-index-cli-0.1.13:\n",
      "      Successfully uninstalled llama-index-cli-0.1.13\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.2.9\n",
      "    Uninstalling llama-index-agent-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.2.9\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.1.7\n",
      "    Uninstalling llama-index-program-openai-0.1.7:\n",
      "      Successfully uninstalled llama-index-program-openai-0.1.7\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.1.3\n",
      "    Uninstalling llama-index-question-gen-openai-0.1.3:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.1.3\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.28\n",
      "    Uninstalling llama-index-0.10.28:\n",
      "      Successfully uninstalled llama-index-0.10.28\n",
      "Successfully installed llama-index-0.12.10 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.10.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.13 llama-index-multi-modal-llms-openai-0.4.2 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.3 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.19 pypdf-5.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-parse in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (0.5.19)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (8.1.8)\n",
      "Requirement already satisfied: llama-index-core>=0.11.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (0.12.10.post1)\n",
      "Requirement already satisfied: pydantic!=2.10 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-parse) (2.10.5)\n",
      "Requirement already satisfied: colorama in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from click<9.0.0,>=8.1.7->llama-parse) (0.4.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2024.12.0)\n",
      "Requirement already satisfied: httpx in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
      "Requirement already satisfied: numpy in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.17.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic!=2.10->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from pydantic!=2.10->llama-parse) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.18.3)\n",
      "Requirement already satisfied: joblib in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.25.1)\n",
      "Requirement already satisfied: anyio in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai_engineer\\doan\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.10.28\n",
    "%pip install llama-index-llms-gemini llama-index\n",
    "%pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-bfQQ5jVwQR1ne8FnmRvSHqNNc7pP9fo4p24QRMS7h74n1w1r\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAxAkyAHaMx7xNxkF5zazokhtZLfp7x6zU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_engineer\\Doan\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.llms.databricks import Databricks\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Ti m hnh embedding\n",
    "#embed_model = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder') \n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-pro\",\n",
    "             api_key=\"AIzaSyAxAkyAHaMx7xNxkF5zazokhtZLfp7x6zU\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tam_li': 'https://igiaoduc.vn/content/uploads/elearning/11qd4216phe-duyet-so-tay-tvtlbgddt-3218329.pdf', 'Dinh_duong': 'https://benhvienthammynaman.com/wp-content/uploads/2024/03/Dinh-duong-chia-khoa-vang-cho-suc-khoe.pdf'}\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://igiaoduc.vn/content/uploads/elearning/11qd4216phe-duyet-so-tay-tvtlbgddt-3218329.pdf\",\n",
    "       \"https://benhvienthammynaman.com/wp-content/uploads/2024/03/Dinh-duong-chia-khoa-vang-cho-suc-khoe.pdf\",\n",
    "       #\"https://viendinhduong.vn/FileUpload/Documents/2020/Dinh%20Duong%20Va%20An%20Toan%20Thuc%20Pham%20-%20Bo%20Y%20Te.pdf\",\n",
    "       #\"https://swsphn.com.au/wp-content/uploads/2022/06/Live_Well_Guide_wb__Vietnamese_LR.pdf\",\n",
    "       ]\n",
    "\n",
    "titles = [\n",
    "    \"Tam_li\",\n",
    "    \"Dinh_duong\",\n",
    "    #\"DD_ATTP\",\n",
    "    #\"Loi_song\"\n",
    "]\n",
    "\n",
    "book_dict = {titles[i]: urls[i] for i in range(len(urls))}\n",
    "print(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 94b276d7-4340-4853-9362-2a8cc982486d\n",
      "### json_objs Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 1\n",
      "Keys of first item: ['pages', 'job_metadata', 'job_id', 'file_path']\n",
      "----------------------\n",
      "### json_list Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 123\n",
      "Keys of first item: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Sample Data (First Item): {'page': 1, 'text': '            Nutrition for Life\\n        Lisa Hark, PhD & Dr; Darwin Deen\\n    Chia khoaDinhduongktoeg\\n      cho sUc\\n3\\n2\\n   PN NHA XUAT BAN PHU NU     NUTRILITE', 'md': '# Nutrition for Life\\n\\n# Lisa Hark, PhD & Dr. Darwin Deen\\n\\nChia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'images': [{'name': 'img_p0_1.png', 'height': 2200, 'width': 1565, 'x': -0.24782300000000035, 'y': 0, 'original_width': 1565, 'original_height': 2200, 'ocr': [{'x': 463, 'y': 47, 'w': 575, 'h': 79, 'confidence': '0.73625183285983', 'text': 'Nutrition for Life'}, {'x': 339, 'y': 148, 'w': 834, 'h': 61, 'confidence': '0.7505294609100561', 'text': 'Lisa Hark, PhD & Dr; Darwin Deen'}, {'x': 311, 'y': 221, 'w': 894, 'h': 266, 'confidence': '0.9989321945557518', 'text': 'Dinhduong'}, {'x': 177, 'y': 432, 'w': 751, 'h': 157, 'confidence': '0.9967959505448877', 'text': 'Chia khoa'}, {'x': 260, 'y': 579, 'w': 577, 'h': 148, 'confidence': '0.8019852041826463', 'text': 'cho sUc'}, {'x': 846, 'y': 428, 'w': 500, 'h': 316, 'confidence': '0.5082430385500368', 'text': 'ktoeg'}, {'x': 6, 'y': 1756, 'w': 52, 'h': 132, 'confidence': '0.25177512642062894', 'text': '3'}, {'x': 1, 'y': 1883, 'w': 61, 'h': 121, 'confidence': '0.5116835424123565', 'text': '2'}, {'x': 157, 'y': 2057, 'w': 50, 'h': 40, 'confidence': '0.8614639207754446', 'text': 'PN'}, {'x': 230, 'y': 2064, 'w': 432, 'h': 52, 'confidence': '0.8886106524629317', 'text': 'NHA XUAT BAN PHU NU'}, {'x': 1080, 'y': 2060, 'w': 372, 'h': 54, 'confidence': '0.8908326294233071', 'text': 'NUTRILITE'}]}], 'charts': [], 'items': [{'type': 'heading', 'lvl': 1, 'value': 'Nutrition for Life', 'md': '# Nutrition for Life', 'bBox': {'x': 180.96, 'y': 16.94, 'w': 225.04, 'h': 28.47}}, {'type': 'heading', 'lvl': 1, 'value': 'Lisa Hark, PhD & Dr. Darwin Deen', 'md': '# Lisa Hark, PhD & Dr. Darwin Deen', 'bBox': {'x': 0, 'y': 0, 'w': 612, 'h': 792}}, {'type': 'text', 'value': 'Chia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'md': 'Chia khoa Dinh duong ktoeg cho sUc\\n\\nPN NHA XUAT BAN PHU NU NUTRILITE', 'bBox': {'x': 61.2, 'y': 154.23, 'w': 506.83, 'h': 608.26}}], 'status': 'OK', 'links': [], 'width': 612, 'height': 792, 'triggeredAutoMode': False, 'structuredData': None, 'noStructuredContent': False, 'noTextContent': False}\n",
      "----------------------\n",
      "Page 1 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 2 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 3 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 4 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 5 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 6 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 7 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 8 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 9 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 10 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 11 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "Page 12 Keys: ['page', 'text', 'md', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent']\n",
      "Metadata Type: <class 'str'> - Page Label Type: <class 'int'>\n",
      "### docs Structure ###\n",
      "Type: <class 'list'>\n",
      "Length: 12\n",
      "Sample Document Metadata: {'page_label': 9}\n",
      "Sample Document Text Type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import Document\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "def _load_data(file_path: str) -> list[Document]:\n",
    "    parser = LlamaParse(result_type=\"text\")\n",
    "    json_objs = parser.get_json_result(file_path)\n",
    "    \n",
    "    # In thng tin c bn ca json_objs\n",
    "    print(\"### json_objs Structure ###\")\n",
    "    print(f\"Type: {type(json_objs)}\")\n",
    "    if isinstance(json_objs, list):\n",
    "        print(f\"Length: {len(json_objs)}\")\n",
    "        print(f\"Keys of first item: {list(json_objs[0].keys())}\")\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    json_list = json_objs[0][\"pages\"]  # Ly danh sch cc trang\n",
    "    print(\"### json_list Structure ###\")\n",
    "    print(f\"Type: {type(json_list)}\")\n",
    "    if isinstance(json_list, list):\n",
    "        print(f\"Length: {len(json_list)}\")\n",
    "        print(f\"Keys of first item: {list(json_list[0].keys())}\")\n",
    "        print(f\"Sample Data (First Item): {json_list[0]}\")\n",
    "\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    docs = []\n",
    "    for i, item in enumerate(json_list[8:20]):  # Ly 10 trang u\n",
    "        print(f\"Page {i + 1} Keys: {list(item.keys())}\")\n",
    "        print(f\"Metadata Type: {type(item['text'])} - Page Label Type: {type(item['page'])}\")\n",
    "        doc = Document(\n",
    "            text=item[\"text\"],\n",
    "            metadata={\"page_label\": item[\"page\"]},\n",
    "        )\n",
    "        docs.append(doc)\n",
    "\n",
    "    print(\"### docs Structure ###\")\n",
    "    print(f\"Type: {type(docs)}\")\n",
    "    print(f\"Length: {len(docs)}\")\n",
    "    if docs:\n",
    "        print(f\"Sample Document Metadata: {docs[0].metadata}\")\n",
    "        print(f\"Sample Document Text Type: {type(docs[0].text)}\")\n",
    "    \n",
    "    return docs\n",
    "documents = _load_data(urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_list = []\n",
    "for title in titles:\n",
    "    docs = _load_data(book_dict[title])\n",
    "    documents_list.append(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'list'>\n",
      "Length: 36\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SentenceSplitter,\n",
    "    SemanticSplitterNodeParser,\n",
    ")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=7, breakpoint_percentile_threshold=50, embed_model=Settings.embed_model\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Type: {type(nodes)}\")\n",
    "if isinstance(nodes, list):\n",
    "    print(f\"Length: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: d0a524a5-cde4-478d-86aa-465cdd7a33ac\n",
      "Text: Bnh m              14              12               74\n",
      "4,1            B1, Fol, Nia/Fe, K, Mg, P, Zn  nguyn cm  Go lt\n",
      "9               10               81                  1,7\n",
      "B1, Nia/Mg, P, Zn  u que              0               9\n",
      "91                  4              A, Fol, K/K  To  ...\n",
      "Node ID: 1d82d735-7e6b-47ae-bbc0-7df72c6293eb\n",
      "Text: Nng Lng T Thc n           Ngoi vic cung cp dng cht,\n",
      "thc n cn       cung cp nng lng cho c th. Khong 1/2 n\n",
      "2/3 s nng lng t thc n c c th dng        duy tr cc\n",
      "chc nng sng c bn  cc hot ng       c thc hin mt cch v\n",
      "thc nh duy tr nhp       tim, ht th, iu ha thn nhit Lng\n",
      "nng ...\n",
      "Node ID: 32575d86-e3e3-4f46-bc93-30c7ad81efa9\n",
      "Text: Tc  chuyn ha t \n",
      "Node ID: 054f54f0-889a-437f-8d0f-0d234651a62f\n",
      "Text: lm vic trong vn phng mc cao nht khi chng ta cn nh v\n",
      "gim                                              dn sau 10 tui. Do\n",
      "nam gii c khi lng c bp nhiu hn nn thng c tc  chuyn\n",
      "ha cao hn, v v vy m cn nhiu nng lng hn ph n. Do khi\n",
      "lng c bp gim dn theo tui tc nn ngi gi c tc  chuyn ha\n",
      "thp hn ...\n",
      "Node ID: ce0d6a4f-9f6a-4295-855f-1cfd43d41d89\n",
      "Text: Tuy nhin, v       1 calo tng ng vi mt lng nng lng\n",
      "rt nh nn n v kil calo       (kcal)thng c s dng.\n",
      "Node ID: fb7f0c70-3a6f-4644-9fdc-c96533d99129\n",
      "Text: (1 kcal = 1.000 cal).\n",
      "Node ID: 3863ea18-d273-44db-918f-e594584dac34\n",
      "Text: Mi loi dng cht sinh ra mt lng nng lng nht nh, v\n",
      "d nh:           100g protein: 400kcal           100g carbohydrate:\n",
      "400kcal           100g cht bo: 900kcal\n",
      "Node ID: db339fdc-84d1-4a0b-93f9-98955dde5ef9\n",
      "Text: C TH X L THC N NH TH NO?     Trc khi c s dng,\n",
      "cc cht dinh dng trong thc n phi c chuyn ha thnh dng n\n",
      "gin m cc t bo trong c th c th hp thu. Qu trnh ny c th\n",
      "mt t mt n ba ngy, bt u t khoang ming v kt thc bng vic\n",
      "tng xut cht thi ra khi c th.     Thc n s tri qua mt qu\n",
      "trnh bi...\n",
      "Node ID: 239446f6-3835-40f2-b3fa-328aa7306db2\n",
      "Text: Phn thc n khng c tiu ha v hp thu s c thi ra\n",
      "ngoi.\n",
      "Node ID: 95d88038-c539-4a12-8dbf-c97e315c1036\n",
      "Text: He tieu hoa                Mieng_\n",
      "Tuyen                                                          nuoc\n",
      "bot        Nap thanh                                             Gan\n",
      "quan               Thuc               quan          Tui mat\n",
      "Ruqt non             Tuyen  ...\n",
      "Node ID: 8d4c4bb0-90d8-4b7d-aebd-c4ad3758f441\n",
      "Text: tiu ha thc n.\n",
      "Node ID: bae15754-eb49-4c56-95e0-ca00a9e7c933\n",
      "Text: Tuyn ty:tit men tiu ha vo rut non.     Trc trng:phn\n",
      "c gi ti y trc khi c thi ra khi c th.      Hu mn:l\n",
      "ni kt thc ca ng tiu ha, m nhim vic thi phn ra ngoi.\n",
      "D dy:thc n lu li trong d dy khong 5 gi  c bp nt v\n",
      "ha ln vi dch v. Trong dch v c cha axit gip tiu dit vi\n",
      "khun trong ...\n",
      "Node ID: bf79480a-e99a-409d-b93d-d54e61e31d41\n",
      "Text: Ti y, thc n c ha trn vi nhiu dch tiu ha na.\n",
      "Node ID: 2072758d-bd29-4f63-a755-e414d6f7cd4b\n",
      "Text: Cc cht dinh dng, bao gm vitamin v khong cht, c hp\n",
      "thu vo mu.\n",
      "Node ID: a1607816-05d5-4da4-97c1-6f161a7a027f\n",
      "Text: Rut gi:trong rut gi c cha nhiu vi khun ng rut gip\n",
      "tip tc tiu ha cc dng cht cn li trong thc n.\n",
      "Node ID: eeecf2f8-1f8d-491f-8711-c5f1c77219cf\n",
      "Text: Nc v cc dng cht do vi khun phn gii c hp thu vo\n",
      "mu.\n",
      "Node ID: 6c97ae99-23bd-4667-96d2-cf45a82bc6d4\n",
      "Text: ____________________     Ch thch:      (*) Enzyme l nhng\n",
      "cht xc tc sinh hc c bn cht l protein.\n",
      "Node ID: c4155a17-a5c9-4b64-b2a2-7d38da0d9a43\n",
      "Text: Chng xc tc cho hu ht cc phn ng chuyn ha din ra trong\n",
      "c th sng.\n",
      "Node ID: 277160d5-8490-41fb-a8f0-518290397749\n",
      "Text: Cht bo  Khng nn qu s!\n",
      "Node ID: 8f7e5f87-34f1-4967-93d0-e5363784868b\n",
      "Text: Cht bo gp phn to thnh mng t bo v ng vai tr cc k\n",
      "quan trng trong vic hp thu cc vitamin tan trong du nh vitamin A,\n",
      "D, E v K.     Cht bo hnh thnh mt lp bo v cho c th, gip duy\n",
      "tr thn nhit  c th khng b nh hng khi nhit  mi trng\n",
      "qu nng hay qu lnh. y cng l ngun nng lng quan trng ca c\n",
      "th\n",
      "Node ID: 76c2a2ae-718c-4948-8704-764df7b1e2eb\n",
      "Text: CHT BO KHNG NN QU S!           L mt phn ca cc hp\n",
      "cht c gi l lipid, cht       bo c tm thy ch yu trong\n",
      "tht, c v mt s loi       thc phm c ngun gc thc vt. Cht\n",
      "bo gp phn       to thnh mng t bo v ng vai tr cc k quan\n",
      "trng trong vic hp thu cc vitamin tan trong du nh       vitamin\n",
      "A, D, ...\n",
      "Node ID: 5959bbcc-2153-4a4e-93b6-ba3856e48809\n",
      "Text: nguy c mc bnh tim mch.     Thc phm cha nhiu cht bo bo\n",
      "ha bao gm: sn phm giu cht bo c ngun gc t sa (b, ph mai,\n",
      "kem, sa nguyn kem), tht c nhiu m, xc xch, m ng vt, nc\n",
      "tht, du c, du da, da ca cc loi gia cm (g, vt).\n",
      "Axit bo                           ...\n",
      "Node ID: 226be6fb-b252-49ec-8902-b769adc8cbaf\n",
      "Text: Cholesterol l mt cht ging nh sp  trong mu.\n",
      "Node ID: b23c2be3-6125-4fa9-b139-0d2f99640170\n",
      "Text: y l thnh t chnh yu ca       vch t bo.\n",
      "Node ID: 6c25694f-a615-4de9-acfb-0977e992c418\n",
      "Text: Cholesterol cng cn cho vic sn sinh cc ni tit t, nh ni\n",
      "tit t       sinh dc  estrogen v testosterone.\n",
      "Node ID: 1c7df12a-986e-4956-8193-4c0f7c701699\n",
      "Text: Cholesterol hin din vi mt  rt cao trong cc t bo.\n",
      "Node ID: d184e332-b463-4219-b0c0-75f6d2e3cc94\n",
      "Text: N c vai tr rt       quan trng l bo v no v h thn\n",
      "kinh.\n",
      "Node ID: 3056d949-0162-4bcb-aeaa-35272883888f\n",
      "Text: V vy, khng cn gii hn lng       cholesterol n vo i\n",
      "vi tr em di hai tui, i tng m no b v h thn       kinh\n",
      "vn ang tip tc pht trin.\n",
      "Node ID: 5ebd767b-ac0a-4e7f-85cd-782268a03a8a\n",
      "Text: Cholesterol cng cn thit cho vic to ra axit mt (h tr cho\n",
      "s hp thu cht       bo t thc n) v cn cho qu trnh sn sinh\n",
      "vitamin D  da.      Phn ln nhu cu cholesterol ca c th c p\n",
      "ng bi chnh lng cholesterol m c th t to ra. Phn cn li c\n",
      "p ng t cholesterol trong thc n (cholesterol c tm thy vi\n",
      "hm l...\n",
      "Node ID: b4fd3d3b-72df-4b9c-8656-c02460ac5efd\n",
      "Text: Hy khoanh trn cu tr li ph hp vi bn nht v kim tra s\n",
      "im ca bn.\n",
      "Node ID: c02efc18-63e8-4c83-bd29-f5442f472724\n",
      "Text: 1.\n",
      "Node ID: 24bce2e9-c2fe-4da0-ab0b-33394d2fe518\n",
      "Text: Bn thng n mn chin (c t du/ngp du) bao nhiu ln?\n",
      "Node ID: 0b66298d-8d6f-465e-b2a8-280f5e1ebe03\n",
      "Text: a) Mi tun ba ln hoc hn           b) Khong mt ln mi tun\n",
      "c) Ti a hai ln mt thng           2.Bn thng dng loi cht bo\n",
      "no  nu nng?\n",
      "Node ID: f5ea0985-1065-46e1-8efd-a6a7c72a9ab0\n",
      "Text: a) B ng vt, m ln, hoc m b     b) B thc vt hoc du\n",
      "thc vt     c) Du  liu hoc du ht nho     3.\n",
      "Node ID: 61a66d55-4bfa-4a4c-bfb0-169c6005895f\n",
      "Text: Bn thng dng loi sa no  ch bin nc xt v cc mn\n",
      "sp, ch?     a) Sa nguyn kem hoc kem     b) Sa tch bo mt phn\n",
      "c) Sa tch bo ton phn     4. Khi nu rau c qu, bn c thm b\n",
      "ng vt vo khng?     a) Lun cho thm b ng vt vo     b) Thi\n",
      "thong c dng b ng vt     c) Khng bao gi cho thm b ng vt\n",
      "vo    ...\n",
      "Node ID: ea492536-d141-49d5-9812-f4b2230ba06e\n",
      "Text: TRC NGHIM\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "for i in range(len(nodes)):\n",
    "    print(nodes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "# cloud\n",
    "cluster_url = \"https://wly3tkm2tkewvzycwne6fa.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "api_key = \"ruGxCkA145k9qWxpoycebKHeLGxc9vtCnLWZ\"\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=cluster_url,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Dinh_duong\", text_key=\"content\")\n",
    "\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dict_keys(['text', 'content', '_node_type', 'page_label', 'document_id', 'relationships', 'ref_doc_id', '_node_content', 'doc_id', 'node_info'])\n",
      "['content', '_node_type', 'page_label', 'document_id', 'ref_doc_id', '_node_content', 'doc_id']\n",
      "{'content': 'lm vic trong vn phng mc cao nht khi chng ta cn nh v gim\\n                                             dn sau 10 tui. Do nam gii c khi lng c\\nbp nhiu hn nn thng c tc  chuyn ha cao hn, v v vy m cn nhiu\\nnng lng hn ph n. Do khi lng c bp gim dn theo tui tc nn ngi\\ngi c tc  chuyn ha thp hn v cn t nng lng hn.\\n\\n    Sau y l cc v d v nhu cu nng lng cho cc hot ng khc nhau \\nngi trng thnh:\\n    Ngi t vn ng: 11,5kcal/ 450g trng lng c th/ngy.\\n\\n    Ngi ch vn ng nh: 13,5kcal/450g trng lng c th/ngy.\\n    Ngi vn ng va phi v tp th dc thng xuyn: 16kcal/450g trng\\nlng c th/ngy.\\n\\n    Ngi vn ng nhiu, nh cc vn ng vin th thao, ngi lao ng chn\\ntay v bnh nhn ang trong qu trnh hi phc: 18kcal/450g trng lng c\\nth/ngy.\\n\\n         Calo v nng lng\\n         Nng lng nhn c t thc n c o bng n v calo (cal). ', '_node_type': 'TextNode', 'page_label': 11.0, 'document_id': UUID('42cfe46a-9ec6-46e3-9e30-e410468ef446'), 'ref_doc_id': '42cfe46a-9ec6-46e3-9e30-e410468ef446', '_node_content': '{\"id_\": \"054f54f0-889a-437f-8d0f-0d234651a62f\", \"embedding\": null, \"metadata\": {\"page_label\": 11}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {\"1\": {\"node_id\": \"42cfe46a-9ec6-46e3-9e30-e410468ef446\", \"node_type\": \"4\", \"metadata\": {\"page_label\": 11}, \"hash\": \"2d9db457b2169620664d3d01f3407202d520deaccf60b35a502fc017fbc4e63f\", \"class_name\": \"RelatedNodeInfo\"}, \"3\": {\"node_id\": \"ce0d6a4f-9f6a-4295-855f-1cfd43d41d89\", \"node_type\": \"1\", \"metadata\": {}, \"hash\": \"e410ca8e94ce48434df92a14782e197a378499d0efc70c4335f0fb0ff558ce2f\", \"class_name\": \"RelatedNodeInfo\"}}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": 0, \"end_char_idx\": 966, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'doc_id': UUID('42cfe46a-9ec6-46e3-9e30-e410468ef446')}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.get(\"Dinh_duong\")\n",
    "\n",
    "i=0\n",
    "for item in collection.iterator():\n",
    "    print(i)\n",
    "    # In danh sch cc keys\n",
    "    print(item.properties.keys())\n",
    "    \n",
    "    # Lc ra cc keys khng phi 'None'\n",
    "    filtered_keys = [key for key in item.properties.keys() if item.properties[key] != None]\n",
    "    print(filtered_keys)\n",
    "    \n",
    "    # In gi tr ca cc keys  lc\n",
    "    filtered_values = {key: item.properties[key] for key in filtered_keys}\n",
    "    print(filtered_values)\n",
    "    print('-'*50)\n",
    "    # i+=1\n",
    "    if (i==0): break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.base.response.schema.Response'>\n",
      "> Source (Doc id: 054f54f0-889a-437f-8d0f-0d234651a62f): lm vic trong vn phng mc cao nht khi chng ta cn nh v gim\n",
      "                              ...\n",
      "\n",
      "> Source (Doc id: 1d82d735-7e6b-47ae-bbc0-7df72c6293eb): Nng Lng T Thc n\n",
      "          Ngoi vic cung cp dng cht, thc n cn\n",
      "      cung cp nng l...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Nhu cu nng lng cho ngi trng thnh t vn ng l 11,5kcal/450g trng lng c th/ngy.  Ngi vn ng nh cn 13,5kcal/450g trng lng c th/ngy.  Ngi vn ng va phi v tp th dc thng xuyn cn 16kcal/450g trng lng c th/ngy.  Cui cng, ngi vn ng nhiu cn 18kcal/450g trng lng c th/ngy.\n",
       "</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Nhu cu nng lng cho cc hot ng  ngi trng thnh l g?\")\n",
    "print(type(response))\n",
    "print(response.get_formatted_sources())\n",
    "from IPython.display import display,Markdown\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
